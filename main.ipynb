{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, DebertaModel, AutoModel, PreTrainedModel\n",
    "\n",
    "def seed(seed_val):\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    # import tensorflow as tf\n",
    "    # tf.random.set_seed(seed_value)\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "seed(42)\n",
    "\n",
    "class deberta:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__name__ = 'microsoft/deberta-base'\n",
    "        self.__num_node_features__ = 768 \n",
    "        self.device = 'cpu'\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
    "# Load model directly\n",
    "        self.model = AutoModel.from_pretrained(\"microsoft/deberta-base\")\n",
    "        # self.model = DebertaModel.from_pretrained(\"microsoft/deberta-base\")\n",
    "        \n",
    "        # self.__output_dim__ = self.__model__.\n",
    "    # @property\n",
    "    def parameters(self):\n",
    "        return self.model.parameters()\n",
    "\n",
    "    @property\n",
    "    def num_node_features(self):\n",
    "        return 768\n",
    "\n",
    "    def to(self, device):\n",
    "        self.model = self.model.to(device)\n",
    "        self.device = device\n",
    "        return self\n",
    "\n",
    "    def forward(self, text):\n",
    "\n",
    "        def model_forward_input(input):\n",
    "            input = self.tokenizer(input, return_tensors='pt').to(self.device)\n",
    "            output = self.model(**input).last_hidden_state.mean(dim=1)\n",
    "            # print(output.shape)\n",
    "            # return self.model(**input).last_hidden_state.mean(dim=1)\n",
    "            # print(output.shape)\n",
    "            return torch.squeeze(output)\n",
    "\n",
    "        return torch.stack(list(map(model_forward_input, text)))\n",
    "\n",
    "    def __call__(self, data):\n",
    "        if isinstance(data, str):\n",
    "            return self.forward([data])\n",
    "        if isinstance(data, list):\n",
    "            return self.forward(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class History(torch.nn.Module):\n",
    "    r\"\"\"A historical embedding storage module.\"\"\"\n",
    "    def __init__(self, num_embeddings: int, embedding_dim: int, device=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        pin_memory = device is None or str(device) == 'cpu'\n",
    "        self.emb = torch.empty(num_embeddings, embedding_dim, device=device,\n",
    "                               pin_memory=pin_memory)\n",
    "\n",
    "        self._device = 'cpu'\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.emb.fill_(0)\n",
    "\n",
    "    def _apply(self, fn):\n",
    "        # Set the `_device` of the module without transfering `self.emb`.\n",
    "        self._device = fn(torch.zeros(1)).device\n",
    "        return self\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def pull(self, n_id: Optional[Tensor] = None) -> Tensor:\n",
    "        out = self.emb\n",
    "        if n_id is not None:\n",
    "            assert n_id.device == self.emb.device\n",
    "            out = out.index_select(0, n_id)\n",
    "        return out.to(device=self._device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def push(self, x, n_id: Optional[Tensor] = None,\n",
    "             offset: Optional[Tensor] = None, count: Optional[Tensor] = None):\n",
    "\n",
    "        if n_id is None and x.size(0) != self.num_embeddings:\n",
    "            raise ValueError\n",
    "\n",
    "        elif n_id is None and x.size(0) == self.num_embeddings:\n",
    "            self.emb.copy_(x)\n",
    "\n",
    "        elif offset is None or count is None:\n",
    "            assert n_id.device == self.emb.device\n",
    "            self.emb[n_id] = x.to(self.emb.device).detach()\n",
    "\n",
    "        else:  # Push in chunks:\n",
    "            src_o = 0\n",
    "            x = x.to(self.emb.device)\n",
    "            for dst_o, c, in zip(offset.tolist(), count.tolist()):\n",
    "                self.emb[dst_o:dst_o + c] = x[src_o:src_o + c]\n",
    "                src_o += c\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        \"\"\"\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.num_embeddings}, '\n",
    "                f'{self.embedding_dim}, emb_device={self.emb.device}, '\n",
    "                f'device={self._device})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = deberta().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "# from ogb.nodeproppred import DglNodePropPredDataset\n",
    "\n",
    "from data_utils import load_data\n",
    "\n",
    "# dataset = dgl.data.CoraGraphDataset()\n",
    "# # device = 'cuda'      # change to 'cuda' for GPU\n",
    "# graph = dataset[0]\n",
    "graph, num_classes, text = load_data('ogbn-arxiv', use_dgl=True, use_text=True)\n",
    "# print(graph.ndata)\n",
    "# print(type(graph))\n",
    "# graph = (dataset)\n",
    "\n",
    "\n",
    "# get text feat\n",
    "# dataset, num_classes, text = load_data('cora', use_dgl=True, use_text=True)\n",
    "# features = []\n",
    "# with torch.no_grad():\n",
    "#     for i, t in enumerate(text):\n",
    "#         if i % 1000 == 0:\n",
    "#             print(i)\n",
    "#         features.append(lm(t).squeeze().cpu())\n",
    "# features = torch.stack(features)\n",
    "# torch.save(features, 'arxiv.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "from ogb.nodeproppred import DglNodePropPredDataset\n",
    "\n",
    "from data_utils import load_data\n",
    "\n",
    "# dataset = dgl.data.CoraGraphDataset()\n",
    "# # device = 'cuda'      # change to 'cuda' for GPU\n",
    "# graph = dataset[0]\n",
    "# graph, num_classes, text = load_data('ogbn-arxiv', use_dgl=True, use_text=True)\n",
    "# print(graph.ndata)\n",
    "# print(type(graph))\n",
    "# graph = (dataset)\n",
    "\n",
    "\n",
    "# get text feat\n",
    "# dataset, num_classes, text = load_data('cora', use_dgl=True, use_text=True)\n",
    "# features = []\n",
    "# with torch.no_grad():\n",
    "#     for t in text:\n",
    "#         features.append(lm(t).squeeze().cpu())\n",
    "# features = torch.stack(features)\n",
    "# torch.save(features, 'arxiv.pt')\n",
    "# print(\"graph.ndata['feat'].shape\", graph.ndata['feat'].shape)\n",
    "# print(\"features.shape\", features.shape)\n",
    "features = torch.load('dataset/arxiv.pt')\n",
    "graph.ndata['x'] = features\n",
    "\n",
    "train_mask = graph.ndata['train_mask']\n",
    "# train_mask = graph.train_mask\n",
    "train_nids = torch.nonzero(train_mask, as_tuple=False).squeeze()\n",
    "val_mask = graph.ndata['val_mask']\n",
    "# val_mask = graph.val_mask\n",
    "val_nids = torch.nonzero(val_mask, as_tuple=False).squeeze()\n",
    "test_mask = graph.ndata['test_mask']\n",
    "# test_mask = graph.test_mask\n",
    "test_nids = torch.nonzero(test_mask, as_tuple=False).squeeze()\n",
    "\n",
    "sampler = dgl.dataloading.NeighborSampler([4, 4])\n",
    "\n",
    "train_dataloader = dgl.dataloading.DataLoader(\n",
    "    # The following arguments are specific to DGL's DataLoader.\n",
    "    graph,              # The graph\n",
    "    train_nids,         # The node IDs to iterate over in minibatches\n",
    "    sampler,            # The neighbor sampler\n",
    "    device=device,      # Put the sampled MFGs on CPU or GPU\n",
    "    # The following arguments are inherited from PyTorch DataLoader.\n",
    "    batch_size=16,    # Batch size\n",
    "    shuffle=True,       # Whether to shuffle the nodes for every epoch\n",
    "    drop_last=True,    # Whether to drop the last incomplete batch\n",
    "    num_workers=0       # Number of sampler processes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from dgl.nn import SAGEConv\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.history = [History(graph.num_nodes(), embedding_dim=in_feats, device='cpu'), History(graph.num_nodes(), embedding_dim=h_feats, device='cpu')]\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, aggregator_type='mean')\n",
    "        self.conv2 = SAGEConv(h_feats, num_classes, aggregator_type='mean')\n",
    "        self.h_feats = h_feats\n",
    "\n",
    "\n",
    "    def push_and_pull(self, history: History, x: Tensor,\n",
    "                      batch_size: Optional[int] = None,\n",
    "                      n_id: Optional[Tensor] = None,\n",
    "                      offset: Optional[Tensor] = None,\n",
    "                      count: Optional[Tensor] = None) -> Tensor:\n",
    "        history.push(x[:batch_size], n_id[:batch_size], offset, count)\n",
    "        h = history.pull(n_id[batch_size:]).to(x.device)\n",
    "        return torch.cat([x[:batch_size], h], dim=0)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward_once(self, mfgs, x):\n",
    "        self.history[0].push(x, mfgs[0].srcdata['_ID'].cpu())\n",
    "        h_dst = x[:mfgs[0].num_dst_nodes()]  # <---\n",
    "        # print(\"h_dst.shape\", h_dst.shape)\n",
    "        h = self.conv1(mfgs[0], (x, h_dst))  # <---\n",
    "        h = F.relu(h)\n",
    "        self.history[1].push(h, mfgs[1].srcdata['_ID'].cpu())\n",
    "\n",
    "\n",
    "    def forward(self, mfgs, x, batch_size):\n",
    "        # Lines that are changed are marked with an arrow: \"<---\"\n",
    "        # print(\"x.shape: \", x.shape)\n",
    "        x = self.push_and_pull(self.history[0], x, batch_size, mfgs[0].srcdata['_ID'].cpu())\n",
    "        # print(\"x.shape: \", x.shape)\n",
    "        h_dst = x[:mfgs[0].num_dst_nodes()]  # <---\n",
    "        # print(\"h_dst.shape\", h_dst.shape)\n",
    "        h = self.conv1(mfgs[0], (x, h_dst))  # <---\n",
    "        h = F.relu(h)\n",
    "        h = self.push_and_pull(self.history[1], h, batch_size, mfgs[1].srcdata['_ID'].cpu())\n",
    "        h_dst = h[:mfgs[1].num_dst_nodes()]  # <---\n",
    "        h = self.conv2(mfgs[1], (h, h_dst))  # <---\n",
    "        return h\n",
    "    \n",
    "    # @torch.no_grad()\n",
    "    # def forward_once(self, mfgs, x, batch_size):\n",
    "    #     with tqdm.tqdm(train_dataloader) as tq:\n",
    "    #         for step, (input_nodes, output_nodes, mfgs) in enumerate(tq):\n",
    "    #             h_dst = x[:mfgs[0].num_dst_nodes()]  # <---\n",
    "    #             # print(\"h_dst.shape\", h_dst.shape)\n",
    "    #             h = self.conv1(mfgs[0], (x, h_dst))  # <---\n",
    "    #             h = F.relu(h)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(in_feats=lm.__num_node_features__, h_feats=64, num_classes=num_classes).to(device)\n",
    "# model = Model(in_feats=1433, h_feats=64, num_classes=7).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = torch.optim.Adam(list(model.parameters())+list(lm.parameters())) # \n",
    "opt = torch.optim.Adam([\n",
    "    {'params': lm.parameters(), 'lr': 1e-4},\n",
    "    {'params': model.parameters(), 'lr': 0.01}])\n",
    "valid_dataloader = dgl.dataloading.DataLoader(\n",
    "    graph, val_nids, sampler,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import sklearn.metrics\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model_path = 'model.pt'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "\n",
    "    with tqdm.tqdm(train_dataloader) as tq:\n",
    "        for step, (input_nodes, output_nodes, mfgs) in enumerate(tq):\n",
    "            if epoch == 0:\n",
    "                inputs = [text[i] for i in input_nodes]\n",
    "                with torch.no_grad():\n",
    "                    x = lm(inputs)\n",
    "                    model.forward_once(mfgs, x)\n",
    "                continue\n",
    "\n",
    "                \n",
    "\n",
    "            # print(111111)\n",
    "            # print(mfgs[0].srcdata)\n",
    "            # inputs = mfgs[0].srcdata['x']\n",
    "            # break\n",
    "            # print(inputs.shape, input_nodes.shape)\n",
    "            inputs = [text[i] for i in output_nodes]\n",
    "            labels = mfgs[-1].dstdata['y']\n",
    "            \n",
    "            inputs = lm(inputs).to(device)\n",
    "            # mfgs = mfgs.to(device)\n",
    "            # print(inputs.shape, labels.shape)\n",
    "            # print(len(labels), inputs.shape, input_nodes.shape, output_nodes.shape)    \n",
    "            # break        \n",
    "            # predictions = model(mfgs, inputs, )\n",
    "            # print(inputs.device, model.device)\n",
    "            predictions = model(mfgs=mfgs, x=inputs, batch_size=16)\n",
    "            labels = torch.flatten(labels)\n",
    "            # print(predictions.device, labels.device)\n",
    "            loss = F.cross_entropy(predictions, labels)\n",
    "            # loss = torch.tensor(0.)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            accuracy = sklearn.metrics.accuracy_score(labels.cpu().numpy(), predictions.argmax(1).detach().cpu().numpy())\n",
    "\n",
    "            tq.set_postfix({'loss': '%.03f' % loss.item(), 'acc': '%.03f' % accuracy}, refresh=False)\n",
    "\n",
    "            del input_nodes, output_nodes, mfgs, inputs, labels, predictions, loss\n",
    "            torch.cuda.empty_cache()\n",
    "            # print(torch.cuda.mem_get_info())\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad() and tqdm.tqdm(valid_dataloader) as tq, torch.no_grad():\n",
    "        for input_nodes, output_nodes, mfgs in tq:\n",
    "            # inputs = [text[i] for i in input_nodes]\n",
    "            # print(type(mfgs[0]))\n",
    "            inputs = mfgs[0].srcdata['x']\n",
    "            labels.append(mfgs[-1].dstdata['y'].cpu().numpy())\n",
    "            # inputs = lm(inputs).to(device)\n",
    "            predictions.append(model(mfgs, inputs).argmax(1).cpu().numpy())\n",
    "        predictions = np.concatenate(predictions)\n",
    "        # print(predictions)\n",
    "        labels = np.concatenate(labels)\n",
    "        accuracy = sklearn.metrics.accuracy_score(labels, predictions)\n",
    "        # print('Epoch {} Validation Accuracy {}'.format(epoch, accuracy))\n",
    "        if best_accuracy < accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        #     inputs = mfgs[0].srcdata['feat']\n",
    "        #     labels.append(mfgs[-1].dstdata['label'].cpu().numpy())\n",
    "        #     predictions.append(model(mfgs, inputs).argmax(1).cpu().numpy())\n",
    "        # predictions = np.concatenate(predictions)\n",
    "        # labels = np.concatenate(labels)\n",
    "        # accuracy = sklearn.metrics.accuracy_score(labels, predictions)\n",
    "        print('Epoch {} Validation Accuracy {} Best Accuracy {}'.format(epoch, accuracy, best_accuracy))\n",
    "        if best_accuracy < accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "        # Note that this tutorial do not train the whole model to the end.\n",
    "        # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
