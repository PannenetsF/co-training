{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/co-training/env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, DebertaModel, AutoModel, PreTrainedModel\n",
    "\n",
    "def seed(seed_val):\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    # import tensorflow as tf\n",
    "    # tf.random.set_seed(seed_value)\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "seed(42)\n",
    "\n",
    "class deberta:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__name__ = 'microsoft/deberta-base'\n",
    "        self.__num_node_features__ = 768 \n",
    "        self.device = 'cpu'\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
    "# Load model directly\n",
    "        self.model = AutoModel.from_pretrained(\"microsoft/deberta-base\")\n",
    "        # self.model = DebertaModel.from_pretrained(\"microsoft/deberta-base\")\n",
    "        \n",
    "        # self.__output_dim__ = self.__model__.\n",
    "    # @property\n",
    "    def parameters(self):\n",
    "        return self.model.parameters()\n",
    "\n",
    "    @property\n",
    "    def num_node_features(self):\n",
    "        return 768\n",
    "\n",
    "    def to(self, device):\n",
    "        self.model = self.model.to(device)\n",
    "        self.device = device\n",
    "        return self\n",
    "\n",
    "    def forward(self, text):\n",
    "\n",
    "        def model_forward_input(input):\n",
    "            input = self.tokenizer(input, return_tensors='pt').to(self.device)\n",
    "            output = self.model(**input).last_hidden_state.mean(dim=1)\n",
    "            # print(output.shape)\n",
    "            # return self.model(**input).last_hidden_state.mean(dim=1)\n",
    "            # print(output.shape)\n",
    "            return torch.squeeze(output)\n",
    "\n",
    "        return torch.stack(list(map(model_forward_input, text)))\n",
    "\n",
    "    def __call__(self, data):\n",
    "        if isinstance(data, str):\n",
    "            return self.forward([data])\n",
    "        if isinstance(data, list):\n",
    "            return self.forward(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/co-training/env/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lm = deberta().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m text:\n\u001b[0;32m---> 22\u001b[0m         features\u001b[38;5;241m.\u001b[39mappend(\u001b[43mlm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m     23\u001b[0m features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(features)\n\u001b[1;32m     24\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(features, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marxiv.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 55\u001b[0m, in \u001b[0;36mdeberta.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 55\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(data)\n",
      "Cell \u001b[0;32mIn[1], line 51\u001b[0m, in \u001b[0;36mdeberta.forward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# print(output.shape)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# return self.model(**input).last_hidden_state.mean(dim=1)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# print(output.shape)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msqueeze(output)\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_forward_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[1], line 45\u001b[0m, in \u001b[0;36mdeberta.forward.<locals>.model_forward_input\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_forward_input\u001b[39m(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\u001b[38;5;28minput\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 45\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# print(output.shape)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# return self.model(**input).last_hidden_state.mean(dim=1)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# print(output.shape)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msqueeze(output)\n",
      "File \u001b[0;32m~/co-training/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/co-training/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/co-training/env/lib/python3.8/site-packages/transformers/models/deberta/modeling_deberta.py:967\u001b[0m, in \u001b[0;36mDebertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    957\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    959\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    960\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    961\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    964\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m    965\u001b[0m )\n\u001b[0;32m--> 967\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m encoded_layers \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/co-training/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/co-training/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/co-training/env/lib/python3.8/site-packages/transformers/models/deberta/modeling_deberta.py:463\u001b[0m, in \u001b[0;36mDebertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    453\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    454\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    455\u001b[0m         next_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    460\u001b[0m         output_attentions,\n\u001b[1;32m    461\u001b[0m     )\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnext_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    473\u001b[0m     hidden_states, att_m \u001b[38;5;241m=\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/co-training/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/co-training/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/co-training/env/lib/python3.8/site-packages/transformers/models/deberta/modeling_deberta.py:376\u001b[0m, in \u001b[0;36mDebertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    369\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    375\u001b[0m ):\n\u001b[0;32m--> 376\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    385\u001b[0m         attention_output, att_matrix \u001b[38;5;241m=\u001b[39m attention_output\n",
      "File \u001b[0;32m~/co-training/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/co-training/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/co-training/env/lib/python3.8/site-packages/transformers/models/deberta/modeling_deberta.py:309\u001b[0m, in \u001b[0;36mDebertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    302\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m     rel_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    308\u001b[0m ):\n\u001b[0;32m--> 309\u001b[0m     self_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    318\u001b[0m         self_output, att_matrix \u001b[38;5;241m=\u001b[39m self_output\n",
      "File \u001b[0;32m~/co-training/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "# from ogb.nodeproppred import DglNodePropPredDataset\n",
    "\n",
    "from data_utils import load_data\n",
    "\n",
    "# dataset = dgl.data.CoraGraphDataset()\n",
    "# # device = 'cuda'      # change to 'cuda' for GPU\n",
    "# graph = dataset[0]\n",
    "graph, num_classes, text = load_data('ogbn-arxiv', use_dgl=True, use_text=True)\n",
    "# print(graph.ndata)\n",
    "# print(type(graph))\n",
    "# graph = (dataset)\n",
    "\n",
    "\n",
    "# get text feat\n",
    "# dataset, num_classes, text = load_data('cora', use_dgl=True, use_text=True)\n",
    "features = []\n",
    "with torch.no_grad():\n",
    "    for i, t in enumerate(text):\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        features.append(lm(t).squeeze().cpu())\n",
    "features = torch.stack(features)\n",
    "torch.save(features, 'arxiv.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "from ogb.nodeproppred import DglNodePropPredDataset\n",
    "\n",
    "from data_utils import load_data\n",
    "\n",
    "# dataset = dgl.data.CoraGraphDataset()\n",
    "# # device = 'cuda'      # change to 'cuda' for GPU\n",
    "# graph = dataset[0]\n",
    "graph, num_classes, text = load_data('ogbn-arxiv', use_dgl=True, use_text=True)\n",
    "# print(graph.ndata)\n",
    "# print(type(graph))\n",
    "# graph = (dataset)\n",
    "\n",
    "\n",
    "# get text feat\n",
    "# dataset, num_classes, text = load_data('cora', use_dgl=True, use_text=True)\n",
    "features = []\n",
    "with torch.no_grad():\n",
    "    for t in text:\n",
    "        features.append(lm(t).squeeze().cpu())\n",
    "features = torch.stack(features)\n",
    "torch.save(features, 'arxiv.pt')\n",
    "# print(\"graph.ndata['feat'].shape\", graph.ndata['feat'].shape)\n",
    "# print(\"features.shape\", features.shape)\n",
    "graph.ndata['x'] = features\n",
    "\n",
    "train_mask = graph.ndata['train_mask']\n",
    "# train_mask = graph.train_mask\n",
    "train_nids = torch.nonzero(train_mask, as_tuple=False).squeeze()\n",
    "val_mask = graph.ndata['val_mask']\n",
    "# val_mask = graph.val_mask\n",
    "val_nids = torch.nonzero(val_mask, as_tuple=False).squeeze()\n",
    "test_mask = graph.ndata['test_mask']\n",
    "# test_mask = graph.test_mask\n",
    "test_nids = torch.nonzero(test_mask, as_tuple=False).squeeze()\n",
    "\n",
    "sampler = dgl.dataloading.NeighborSampler([4, 4])\n",
    "\n",
    "train_dataloader = dgl.dataloading.DataLoader(\n",
    "    # The following arguments are specific to DGL's DataLoader.\n",
    "    graph,              # The graph\n",
    "    train_nids,         # The node IDs to iterate over in minibatches\n",
    "    sampler,            # The neighbor sampler\n",
    "    device=device,      # Put the sampled MFGs on CPU or GPU\n",
    "    # The following arguments are inherited from PyTorch DataLoader.\n",
    "    batch_size=8,    # Batch size\n",
    "    shuffle=True,       # Whether to shuffle the nodes for every epoch\n",
    "    drop_last=True,    # Whether to drop the last incomplete batch\n",
    "    num_workers=0       # Number of sampler processes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import SAGEConv\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, aggregator_type='mean')\n",
    "        self.conv2 = SAGEConv(h_feats, num_classes, aggregator_type='mean')\n",
    "        self.h_feats = h_feats\n",
    "\n",
    "    def forward(self, mfgs, x):\n",
    "        # Lines that are changed are marked with an arrow: \"<---\"\n",
    "        \n",
    "        h_dst = x[:mfgs[0].num_dst_nodes()]  # <---\n",
    "        h = self.conv1(mfgs[0], (x, h_dst))  # <---\n",
    "        h = F.relu(h)\n",
    "        h_dst = h[:mfgs[1].num_dst_nodes()]  # <---\n",
    "        h = self.conv2(mfgs[1], (h, h_dst))  # <---\n",
    "        return h\n",
    "\n",
    "model = Model(in_feats=lm.__num_node_features__, h_feats=64, num_classes=7).to(device)\n",
    "# model = Model(in_feats=1433, h_feats=64, num_classes=7).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = torch.optim.Adam(list(model.parameters())+list(lm.parameters())) # \n",
    "opt = torch.optim.Adam([\n",
    "    # {'params': lm.parameters(), 'lr': 1e-4},\n",
    "    {'params': model.parameters(), 'lr': 0.01}])\n",
    "valid_dataloader = dgl.dataloading.DataLoader(\n",
    "    graph, val_nids, sampler,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 126.29it/s, loss=1.706, acc=0.125]\n",
      "100%|██████████| 9/9 [00:00<00:00, 183.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Validation Accuracy 0.3726937269372694 Best Accuracy 0.3726937269372694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 133.49it/s, loss=1.360, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 174.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation Accuracy 0.4317343173431734 Best Accuracy 0.4317343173431734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 136.22it/s, loss=1.266, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 180.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation Accuracy 0.43726937269372695 Best Accuracy 0.43726937269372695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.99it/s, loss=1.232, acc=0.375]\n",
      "100%|██████████| 9/9 [00:00<00:00, 188.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation Accuracy 0.44095940959409596 Best Accuracy 0.44095940959409596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 135.82it/s, loss=1.813, acc=0.125]\n",
      "100%|██████████| 9/9 [00:00<00:00, 155.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Validation Accuracy 0.3118081180811808 Best Accuracy 0.44095940959409596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 135.54it/s, loss=1.585, acc=0.250]\n",
      "100%|██████████| 9/9 [00:00<00:00, 40.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Validation Accuracy 0.45940959409594095 Best Accuracy 0.45940959409594095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 132.65it/s, loss=1.210, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 167.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Validation Accuracy 0.43357933579335795 Best Accuracy 0.45940959409594095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.44it/s, loss=1.097, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 189.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Validation Accuracy 0.4151291512915129 Best Accuracy 0.45940959409594095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 132.43it/s, loss=0.712, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 176.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Validation Accuracy 0.4612546125461255 Best Accuracy 0.4612546125461255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 130.77it/s, loss=1.076, acc=0.750]\n",
      "100%|██████████| 9/9 [00:00<00:00, 164.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Validation Accuracy 0.477859778597786 Best Accuracy 0.477859778597786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 136.18it/s, loss=0.919, acc=0.750]\n",
      "100%|██████████| 9/9 [00:00<00:00, 164.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Validation Accuracy 0.43726937269372695 Best Accuracy 0.477859778597786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 135.93it/s, loss=1.139, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 159.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Validation Accuracy 0.4483394833948339 Best Accuracy 0.477859778597786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.64it/s, loss=1.266, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 163.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Validation Accuracy 0.470479704797048 Best Accuracy 0.477859778597786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 138.14it/s, loss=0.819, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 195.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Validation Accuracy 0.45940959409594095 Best Accuracy 0.477859778597786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 130.03it/s, loss=1.703, acc=0.375]\n",
      "100%|██████████| 9/9 [00:00<00:00, 159.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Validation Accuracy 0.4612546125461255 Best Accuracy 0.477859778597786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 130.22it/s, loss=1.110, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 161.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Validation Accuracy 0.4261992619926199 Best Accuracy 0.477859778597786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 137.41it/s, loss=1.584, acc=0.250]\n",
      "100%|██████████| 9/9 [00:00<00:00, 169.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Validation Accuracy 0.4612546125461255 Best Accuracy 0.477859778597786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 112.86it/s, loss=1.273, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 149.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Validation Accuracy 0.47232472324723246 Best Accuracy 0.477859778597786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 130.87it/s, loss=0.880, acc=0.750]\n",
      "100%|██████████| 9/9 [00:00<00:00, 179.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Validation Accuracy 0.46309963099630996 Best Accuracy 0.477859778597786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 130.22it/s, loss=0.749, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 168.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Validation Accuracy 0.4612546125461255 Best Accuracy 0.477859778597786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 135.03it/s, loss=0.755, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 184.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Validation Accuracy 0.45940959409594095 Best Accuracy 0.477859778597786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.57it/s, loss=1.535, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 202.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Validation Accuracy 0.39114391143911437 Best Accuracy 0.477859778597786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 133.80it/s, loss=1.682, acc=0.125]\n",
      "100%|██████████| 9/9 [00:00<00:00, 170.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Validation Accuracy 0.45387453874538747 Best Accuracy 0.477859778597786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 132.49it/s, loss=0.755, acc=1.000]\n",
      "100%|██████████| 9/9 [00:00<00:00, 179.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Validation Accuracy 0.4981549815498155 Best Accuracy 0.4981549815498155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 137.24it/s, loss=0.708, acc=0.750]\n",
      "100%|██████████| 9/9 [00:00<00:00, 189.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Validation Accuracy 0.4833948339483395 Best Accuracy 0.4981549815498155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 135.57it/s, loss=1.116, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 180.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Validation Accuracy 0.45202952029520294 Best Accuracy 0.4981549815498155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 135.50it/s, loss=1.341, acc=0.375]\n",
      "100%|██████████| 9/9 [00:00<00:00, 163.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Validation Accuracy 0.474169741697417 Best Accuracy 0.4981549815498155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 133.29it/s, loss=1.136, acc=0.375]\n",
      "100%|██████████| 9/9 [00:00<00:00, 195.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Validation Accuracy 0.4483394833948339 Best Accuracy 0.4981549815498155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 128.95it/s, loss=1.683, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 190.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Validation Accuracy 0.42066420664206644 Best Accuracy 0.4981549815498155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 136.52it/s, loss=1.504, acc=0.250]\n",
      "100%|██████████| 9/9 [00:00<00:00, 167.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Validation Accuracy 0.45387453874538747 Best Accuracy 0.4981549815498155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 133.69it/s, loss=1.559, acc=0.250]\n",
      "100%|██████████| 9/9 [00:00<00:00, 180.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Validation Accuracy 0.37453874538745385 Best Accuracy 0.4981549815498155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.74it/s, loss=0.954, acc=0.750]\n",
      "100%|██████████| 9/9 [00:00<00:00, 204.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Validation Accuracy 0.3985239852398524 Best Accuracy 0.4981549815498155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.86it/s, loss=2.091, acc=0.250]\n",
      "100%|██████████| 9/9 [00:00<00:00, 163.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Validation Accuracy 0.474169741697417 Best Accuracy 0.4981549815498155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 133.43it/s, loss=1.243, acc=0.375]\n",
      "100%|██████████| 9/9 [00:00<00:00, 164.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Validation Accuracy 0.514760147601476 Best Accuracy 0.514760147601476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 137.58it/s, loss=1.340, acc=0.375]\n",
      "100%|██████████| 9/9 [00:00<00:00, 176.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Validation Accuracy 0.466789667896679 Best Accuracy 0.514760147601476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.97it/s, loss=2.045, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 167.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Validation Accuracy 0.4132841328413284 Best Accuracy 0.514760147601476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 131.63it/s, loss=1.191, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 172.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Validation Accuracy 0.46494464944649444 Best Accuracy 0.514760147601476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 132.79it/s, loss=1.585, acc=0.250]\n",
      "100%|██████████| 9/9 [00:00<00:00, 181.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Validation Accuracy 0.4870848708487085 Best Accuracy 0.514760147601476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 117.99it/s, loss=1.274, acc=0.375]\n",
      "100%|██████████| 9/9 [00:00<00:00, 165.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Validation Accuracy 0.4981549815498155 Best Accuracy 0.514760147601476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 132.03it/s, loss=1.654, acc=0.250]\n",
      "100%|██████████| 9/9 [00:00<00:00, 152.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Validation Accuracy 0.5202952029520295 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 113.58it/s, loss=0.861, acc=0.750]\n",
      "100%|██████████| 9/9 [00:00<00:00, 166.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Validation Accuracy 0.45571955719557194 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 130.26it/s, loss=1.301, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 164.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Validation Accuracy 0.48523985239852396 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 129.01it/s, loss=1.834, acc=0.250]\n",
      "100%|██████████| 9/9 [00:00<00:00, 162.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Validation Accuracy 0.4907749077490775 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 130.19it/s, loss=1.215, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 161.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Validation Accuracy 0.46309963099630996 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 129.69it/s, loss=1.417, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 172.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Validation Accuracy 0.466789667896679 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 131.99it/s, loss=0.863, acc=0.750]\n",
      "100%|██████████| 9/9 [00:00<00:00, 176.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Validation Accuracy 0.4114391143911439 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 135.78it/s, loss=1.346, acc=0.375]\n",
      "100%|██████████| 9/9 [00:00<00:00, 201.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Validation Accuracy 0.45940959409594095 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 132.93it/s, loss=1.424, acc=0.250]\n",
      "100%|██████████| 9/9 [00:00<00:00, 168.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Validation Accuracy 0.4077490774907749 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.71it/s, loss=1.322, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 154.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Validation Accuracy 0.466789667896679 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 135.80it/s, loss=1.432, acc=0.750]\n",
      "100%|██████████| 9/9 [00:00<00:00, 183.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Validation Accuracy 0.46494464944649444 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.39it/s, loss=1.164, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 166.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Validation Accuracy 0.47601476014760147 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 136.73it/s, loss=0.659, acc=0.875]\n",
      "100%|██████████| 9/9 [00:00<00:00, 179.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Validation Accuracy 0.477859778597786 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 135.71it/s, loss=1.044, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 159.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Validation Accuracy 0.46863468634686345 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.87it/s, loss=1.172, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 174.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Validation Accuracy 0.46863468634686345 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 137.27it/s, loss=0.995, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 191.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Validation Accuracy 0.46494464944649444 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.13it/s, loss=1.370, acc=0.375]\n",
      "100%|██████████| 9/9 [00:00<00:00, 172.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Validation Accuracy 0.3062730627306273 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 133.10it/s, loss=0.755, acc=0.750]\n",
      "100%|██████████| 9/9 [00:00<00:00, 165.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Validation Accuracy 0.47232472324723246 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 123.70it/s, loss=1.183, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 181.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Validation Accuracy 0.470479704797048 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 135.99it/s, loss=1.527, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 147.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Validation Accuracy 0.45018450184501846 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 119.27it/s, loss=1.103, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 171.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Validation Accuracy 0.42988929889298894 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 123.72it/s, loss=0.974, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 180.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Validation Accuracy 0.4797047970479705 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 127.32it/s, loss=1.365, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 172.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Validation Accuracy 0.46494464944649444 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 127.55it/s, loss=1.384, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 165.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Validation Accuracy 0.48154981549815495 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 129.43it/s, loss=1.095, acc=0.375]\n",
      "100%|██████████| 9/9 [00:00<00:00, 181.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Validation Accuracy 0.48523985239852396 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 130.90it/s, loss=1.067, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 176.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Validation Accuracy 0.466789667896679 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 129.99it/s, loss=0.729, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 174.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Validation Accuracy 0.48154981549815495 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 130.60it/s, loss=1.372, acc=0.375]\n",
      "100%|██████████| 9/9 [00:00<00:00, 166.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Validation Accuracy 0.48523985239852396 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 137.68it/s, loss=1.067, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 178.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Validation Accuracy 0.45940959409594095 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 133.17it/s, loss=0.680, acc=0.875]\n",
      "100%|██████████| 9/9 [00:00<00:00, 157.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Validation Accuracy 0.466789667896679 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.06it/s, loss=1.382, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 172.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Validation Accuracy 0.4797047970479705 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 137.94it/s, loss=1.053, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 194.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Validation Accuracy 0.45387453874538747 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 135.56it/s, loss=1.013, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 184.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Validation Accuracy 0.474169741697417 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.65it/s, loss=1.021, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 174.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Validation Accuracy 0.43726937269372695 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.10it/s, loss=1.193, acc=0.750]\n",
      "100%|██████████| 9/9 [00:00<00:00, 181.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Validation Accuracy 0.4612546125461255 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 135.78it/s, loss=1.096, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 181.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Validation Accuracy 0.46863468634686345 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 135.00it/s, loss=1.212, acc=0.375]\n",
      "100%|██████████| 9/9 [00:00<00:00, 180.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Validation Accuracy 0.43357933579335795 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.35it/s, loss=0.624, acc=0.750]\n",
      "100%|██████████| 9/9 [00:00<00:00, 168.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Validation Accuracy 0.466789667896679 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 132.73it/s, loss=0.792, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 180.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Validation Accuracy 0.474169741697417 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 132.81it/s, loss=1.097, acc=0.375]\n",
      "100%|██████████| 9/9 [00:00<00:00, 174.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Validation Accuracy 0.5129151291512916 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 132.95it/s, loss=1.119, acc=0.375]\n",
      "100%|██████████| 9/9 [00:00<00:00, 183.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Validation Accuracy 0.42988929889298894 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 119.30it/s, loss=1.016, acc=0.375]\n",
      "100%|██████████| 9/9 [00:00<00:00, 181.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Validation Accuracy 0.514760147601476 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 136.81it/s, loss=0.926, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 186.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Validation Accuracy 0.45387453874538747 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 109.73it/s, loss=0.694, acc=0.750]\n",
      "100%|██████████| 9/9 [00:00<00:00, 160.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Validation Accuracy 0.4483394833948339 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 133.50it/s, loss=1.129, acc=0.375]\n",
      "100%|██████████| 9/9 [00:00<00:00, 173.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Validation Accuracy 0.488929889298893 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 126.51it/s, loss=1.013, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 196.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Validation Accuracy 0.48154981549815495 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 126.67it/s, loss=0.875, acc=0.750]\n",
      "100%|██████████| 9/9 [00:00<00:00, 163.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Validation Accuracy 0.4483394833948339 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 133.37it/s, loss=1.734, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 180.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Validation Accuracy 0.477859778597786 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.15it/s, loss=2.592, acc=0.125]\n",
      "100%|██████████| 9/9 [00:00<00:00, 192.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Validation Accuracy 0.48154981549815495 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 132.57it/s, loss=0.935, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 170.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Validation Accuracy 0.47601476014760147 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 138.27it/s, loss=1.389, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 172.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Validation Accuracy 0.46494464944649444 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 135.32it/s, loss=0.952, acc=0.750]\n",
      "100%|██████████| 9/9 [00:00<00:00, 169.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Validation Accuracy 0.4797047970479705 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 137.33it/s, loss=1.269, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 174.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Validation Accuracy 0.5092250922509225 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 136.27it/s, loss=1.337, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 170.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Validation Accuracy 0.45387453874538747 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.91it/s, loss=1.044, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 174.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Validation Accuracy 0.48154981549815495 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 135.07it/s, loss=0.925, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 187.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Validation Accuracy 0.45571955719557194 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 138.14it/s, loss=1.177, acc=0.375]\n",
      "100%|██████████| 9/9 [00:00<00:00, 178.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Validation Accuracy 0.3154981549815498 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 137.34it/s, loss=1.170, acc=0.250]\n",
      "100%|██████████| 9/9 [00:00<00:00, 187.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Validation Accuracy 0.46494464944649444 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 137.59it/s, loss=1.143, acc=0.500]\n",
      "100%|██████████| 9/9 [00:00<00:00, 191.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Validation Accuracy 0.466789667896679 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 134.47it/s, loss=0.747, acc=0.750]\n",
      "100%|██████████| 9/9 [00:00<00:00, 170.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Validation Accuracy 0.46863468634686345 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [00:01<00:00, 135.92it/s, loss=1.035, acc=0.625]\n",
      "100%|██████████| 9/9 [00:00<00:00, 163.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Validation Accuracy 0.47601476014760147 Best Accuracy 0.5202952029520295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import sklearn.metrics\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model_path = 'model.pt'\n",
    "\n",
    "dataset, num_classes, text = load_data('cora', use_dgl=True, use_text=True)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "\n",
    "    with tqdm.tqdm(train_dataloader) as tq:\n",
    "        for step, (input_nodes, output_nodes, mfgs) in enumerate(tq):\n",
    "            # print(mfgs[0].srcdata)\n",
    "            inputs = mfgs[0].srcdata['x']\n",
    "            # print(inputs.shape, input_nodes.shape)\n",
    "            # inputs = [text[i] for i in input_nodes]\n",
    "            # inputs = lm(inputs).to(device)\n",
    "            # mfgs = mfgs.to(device)\n",
    "            labels = mfgs[-1].dstdata['y']\n",
    "            # print(inputs.shape, labels.shape)\n",
    "            # print(len(labels), inputs.shape, input_nodes.shape, output_nodes.shape)    \n",
    "            # break        \n",
    "            predictions = model(mfgs, inputs)\n",
    "\n",
    "            loss = F.cross_entropy(predictions, labels)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            accuracy = sklearn.metrics.accuracy_score(labels.cpu().numpy(), predictions.argmax(1).detach().cpu().numpy())\n",
    "\n",
    "            tq.set_postfix({'loss': '%.03f' % loss.item(), 'acc': '%.03f' % accuracy}, refresh=False)\n",
    "\n",
    "            del input_nodes, output_nodes, mfgs, inputs, labels, predictions, loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad() and tqdm.tqdm(valid_dataloader) as tq, torch.no_grad():\n",
    "        for input_nodes, output_nodes, mfgs in tq:\n",
    "            # inputs = [text[i] for i in input_nodes]\n",
    "            # print(type(mfgs[0]))\n",
    "            inputs = mfgs[0].srcdata['x']\n",
    "            labels.append(mfgs[-1].dstdata['y'].cpu().numpy())\n",
    "            # inputs = lm(inputs).to(device)\n",
    "            predictions.append(model(mfgs, inputs).argmax(1).cpu().numpy())\n",
    "        predictions = np.concatenate(predictions)\n",
    "        # print(predictions)\n",
    "        labels = np.concatenate(labels)\n",
    "        accuracy = sklearn.metrics.accuracy_score(labels, predictions)\n",
    "        # print('Epoch {} Validation Accuracy {}'.format(epoch, accuracy))\n",
    "        if best_accuracy < accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        #     inputs = mfgs[0].srcdata['feat']\n",
    "        #     labels.append(mfgs[-1].dstdata['label'].cpu().numpy())\n",
    "        #     predictions.append(model(mfgs, inputs).argmax(1).cpu().numpy())\n",
    "        # predictions = np.concatenate(predictions)\n",
    "        # labels = np.concatenate(labels)\n",
    "        # accuracy = sklearn.metrics.accuracy_score(labels, predictions)\n",
    "        print('Epoch {} Validation Accuracy {} Best Accuracy {}'.format(epoch, accuracy, best_accuracy))\n",
    "        if best_accuracy < accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "        # Note that this tutorial do not train the whole model to the end.\n",
    "        # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
