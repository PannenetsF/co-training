{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ericyu8817/env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import tqdm\n",
    "from typing import Optional\n",
    "from argparse import Namespace\n",
    "import json\n",
    "import types\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import dgl\n",
    "\n",
    "from cotraining import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_namespace(d):\n",
    "    \"\"\"\n",
    "    Recursively converts a dictionary to a SimpleNamespace.\n",
    "    \n",
    "    Args:\n",
    "        d (dict): The dictionary to convert.\n",
    "        \n",
    "    Returns:\n",
    "        SimpleNamespace: The converted namespace.\n",
    "    \"\"\"\n",
    "    if isinstance(d, dict):\n",
    "        # Convert sub-dictionaries to SimpleNamespace recursively\n",
    "        return types.SimpleNamespace(**{k: dict_to_namespace(v) for k, v in d.items()})\n",
    "    else:\n",
    "        # Return non-dictionary values as-is\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training params:\n",
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"device\": 'cuda',\n",
    "    \"epoch\": 2000,\n",
    "\n",
    "    \"lm_type\": 'deberta-base',\n",
    "    \"lm_lr\": 1e-4,\n",
    "    \"lm_max_length\": 512,\n",
    "    \"lm_weight_decay\": 1e-4,\n",
    "    \"lm_padding\": True,\n",
    "    \"lm_truncation\": True,\n",
    "    \"lm_requires_grad\": False,\n",
    "    \"pooler_hidden_size\": 128, \n",
    "    \"pooler_dropout\": 0.5,\n",
    "    \"pooler_hidden_act\": 'relu',\n",
    "\n",
    "    \"num_nodes\": 169343,\n",
    "    \"num_node_features\": 128,\n",
    "    \"gnn_h_feats\": 256,\n",
    "    \"gnn_lr\": 0.0005,\n",
    "    \"gnn_weight_decay\": 0,\n",
    "    \"gnn_dropout\": 0.5,\n",
    "    \"gnn_requires_grad\": True,\n",
    "    \"gnn_num_layers\":7,\n",
    "\n",
    "    \"once_batch_size\": 64,\n",
    "    \"once_shuffle\": True,\n",
    "    \"once_drop_last\": True,\n",
    "\n",
    "    \"train_batch_size\": 1024,\n",
    "    \"train_shuffle\": True,\n",
    "    \"train_drop_last\": True,\n",
    "\n",
    "    \"valid_batch_size\": 1024,\n",
    "    \"valid_shuffle\": True,\n",
    "    \"valid_drop_last\": True,\n",
    "\n",
    "    \"test_batch_size\": 1024,\n",
    "    \"test_shuffle\": True,\n",
    "    \"test_drop_last\": True,\n",
    "}\n",
    "\n",
    "config = dict_to_namespace(config)\n",
    "config.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(config.seed)\n",
    "\n",
    "\n",
    "# with open('config/arxiv.json') as file:\n",
    "#     config = json.loads(file.read())\n",
    "# config = dict_to_namespace(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ericyu8817/env/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lm = deberta(config).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, num_classes, text = load_data('ogbn-arxiv', use_dgl=True, use_text=True)\n",
    "graph = dgl.to_bidirected(graph, copy_ndata=True)\n",
    "graph = dgl.remove_self_loop(graph)\n",
    "graph = dgl.add_self_loop(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169343"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = torch.load('arxiv_deberta.pt')\n",
    "# graph.ndata['x'] = torch.squeeze(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([169343, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.ndata['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = graphsage(num_nodes=graph.num_nodes(), in_feats=lm.__num_node_features__, h_feats=64, num_classes=num_classes).to(config.device)\n",
    "model = graphsage(num_layers=config.gnn_num_layers, num_nodes=config.num_nodes, in_feats=config.num_node_features, h_feats=config.gnn_h_feats, num_classes=num_classes, dropout=config.gnn_dropout).to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in lm.parameters():\n",
    "    param.requires_grad = config.lm_requires_grad\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = config.gnn_requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = torch.optim.Adam(list(model.parameters())+list(lm.parameters())) # \n",
    "opt = torch.optim.Adam([\n",
    "    {'params': lm.parameters(), 'lr': config.lm_lr, \"weight_decay\": config.lm_weight_decay},\n",
    "    {'params': model.parameters(), 'lr': config.gnn_lr, \"weight_decay\": config.gnn_weight_decay}])\n",
    "\n",
    "train_dataloader, valid_dataloader, test_dataloader = init_dataloader(graph, 'once', config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# forward_once(train_dataloader, model)\n",
    "# forward_once(valid_dataloader, model)\n",
    "# forward_once(test_dataloader, model)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader = init_dataloader(graph, 'train', config), init_dataloader(graph, 'val', config), init_dataloader(graph, 'test', config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:22<00:00,  3.87it/s, loss=4.198, acc=0.097]\n",
      "100%|██████████| 29/29 [00:05<00:00,  4.84it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Valid Accuracy 0.1892847521551724  Best Accuracy 0.1892847521551724 Test Accuracy 0.17524102393617022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:22<00:00,  3.88it/s, loss=3.193, acc=0.137]\n",
      "100%|██████████| 29/29 [00:05<00:00,  4.94it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Valid Accuracy 0.23094019396551724  Best Accuracy 0.23094019396551724 Test Accuracy 0.2176695478723404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:22<00:00,  3.91it/s, loss=3.023, acc=0.147]\n",
      "100%|██████████| 29/29 [00:05<00:00,  5.01it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Valid Accuracy 0.23036772629310345  Best Accuracy 0.23094019396551724 Test Accuracy 0.21663065159574468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:22<00:00,  3.90it/s, loss=2.983, acc=0.194]\n",
      "100%|██████████| 29/29 [00:05<00:00,  5.01it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Valid Accuracy 0.23013200431034483  Best Accuracy 0.23094019396551724 Test Accuracy 0.21665142952127658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:22<00:00,  3.91it/s, loss=2.932, acc=0.217]\n",
      "100%|██████████| 29/29 [00:05<00:00,  4.97it/s]\n",
      "100%|██████████| 47/47 [00:09<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Valid Accuracy 0.23080549568965517  Best Accuracy 0.23094019396551724 Test Accuracy 0.21752410239361702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 4/88 [00:01<00:31,  2.67it/s, loss=2.938, acc=0.209]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m         tq\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%.03f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%.03f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m accuracy}, refresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m input_nodes, output_nodes, mfgs, inputs, labels, predictions, loss\n\u001b[0;32m---> 58\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;66;03m# print(torch.cuda.mem_get_info())\u001b[39;00m\n\u001b[1;32m     60\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/env/lib/python3.8/site-packages/torch/cuda/memory.py:162\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# with tqdm.tqdm(train_dataloader) as tq:\n",
    "#     for step, (input_nodes, output_nodes, mfgs) in enumerate(tq):\n",
    "#         # inputs = [text[i] for i in input_nodes]\n",
    "#         with torch.no_grad():\n",
    "#             # x = lm(inputs)\n",
    "#             x = mfgs[0].srcdata['x']\n",
    "#             model.forward_once(mfgs, x)\n",
    "\n",
    "# with tqdm.tqdm(valid_dataloader) as tq:\n",
    "#     for step, (input_nodes, output_nodes, mfgs) in enumerate(tq):\n",
    "#         # inputs = [text[i] for i in input_nodes]\n",
    "#         with torch.no_grad():\n",
    "#             # x = lm(inputs)\n",
    "#             x = mfgs[0].srcdata['x']\n",
    "#             model.forward_once(mfgs, x)\n",
    "\n",
    "# with tqdm.tqdm(test_dataloader) as tq:\n",
    "#     for step, (input_nodes, output_nodes, mfgs) in enumerate(tq):\n",
    "#         # inputs = [text[i] for i in input_nodes]\n",
    "#         with torch.no_grad():\n",
    "#             # x = lm(inputs)\n",
    "#             x = mfgs[0].srcdata['x']\n",
    "#             model.forward_once(mfgs, x)\n",
    "\n",
    "best_val_accuracy = 0.\n",
    "best_model_path = 'model.pt'\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "\n",
    "    with tqdm.tqdm(train_dataloader) as tq:\n",
    "        for step, (input_nodes, output_nodes, mfgs) in enumerate(tq):\n",
    "            # print(output_nodes)\n",
    "            # inputs = [text[i] for i in output_nodes]\n",
    "            labels = mfgs[-1].dstdata['y']\n",
    "            \n",
    "            # inputs = lm(inputs).to(config.device)\n",
    "            inputs = mfgs[0].srcdata['x']\n",
    "\n",
    "            # print(inputs.shape, input_nodes.shape, output_nodes.shape, labels.shape)\n",
    "\n",
    "            # predictions = model(mfgs=mfgs, x=inputs, batch_size=config.train_batch_size)\n",
    "            predictions = model(mfgs=mfgs, x=inputs)\n",
    "            labels = torch.flatten(labels)\n",
    "            # print(predictions.device, labels.device)\n",
    "            loss = F.cross_entropy(predictions, labels)\n",
    "            # loss = torch.tensor(0.)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            accuracy = sklearn.metrics.accuracy_score(labels.cpu().numpy(), predictions.argmax(1).detach().cpu().numpy())\n",
    "\n",
    "            tq.set_postfix({'loss': '%.03f' % loss.item(), 'acc': '%.03f' % accuracy}, refresh=False)\n",
    "\n",
    "            del input_nodes, output_nodes, mfgs, inputs, labels, predictions, loss\n",
    "            torch.cuda.empty_cache()\n",
    "            # print(torch.cuda.mem_get_info())\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad() and tqdm.tqdm(valid_dataloader) as tq, torch.no_grad():\n",
    "        for input_nodes, output_nodes, mfgs in tq:\n",
    "            inputs = mfgs[0].srcdata['x']\n",
    "            labels.append(mfgs[-1].dstdata['y'].cpu().numpy())\n",
    "            # predictions.append(model(mfgs=mfgs, x=inputs, batch_size=config.valid_batch_size).argmax(1).cpu().numpy())\n",
    "            predictions.append(model(mfgs=mfgs, x=inputs).argmax(1).cpu().numpy())\n",
    "        predictions = np.concatenate(predictions)\n",
    "        labels = np.concatenate(labels)\n",
    "        val_accuracy = sklearn.metrics.accuracy_score(labels, predictions)\n",
    "        if best_val_accuracy <= val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model, best_model_path)\n",
    "\n",
    "    best_model = torch.load(best_model_path)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad() and tqdm.tqdm(test_dataloader) as tq, torch.no_grad():\n",
    "        for input_nodes, output_nodes, mfgs in tq:\n",
    "            # inputs = [text[i] for i in input_nodes]\n",
    "            # print(type(mfgs[0]))\n",
    "            inputs = mfgs[0].srcdata['x']\n",
    "            labels.append(mfgs[-1].dstdata['y'].cpu().numpy())\n",
    "            # inputs = lm(inputs).to(device)\n",
    "            predictions.append(model(mfgs=mfgs, x=inputs).argmax(1).cpu().numpy())\n",
    "            # predictions.append(model(mfgs=mfgs, x=inputs, batch_size=config.test_batch_size).argmax(1).cpu().numpy())\n",
    "        predictions = np.concatenate(predictions)\n",
    "        # print(predictions)\n",
    "        labels = np.concatenate(labels)\n",
    "        test_accuracy = sklearn.metrics.accuracy_score(labels, predictions)\n",
    "\n",
    "        # with open('log.txt', 'a') as file:\n",
    "        #     file.write('Epoch {} Valid Accuracy {}  Best Accuracy {} Test Accuracy {}\\n'.format(epoch, val_accuracy, best_val_accuracy, test_accuracy))\n",
    "\n",
    "        print('Epoch {} Valid Accuracy {}  Best Accuracy {} Test Accuracy {}'.format(epoch, val_accuracy, best_val_accuracy, test_accuracy))\n",
    "        # Note that this tutorial do not train the whole model to the end.\n",
    "        # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
